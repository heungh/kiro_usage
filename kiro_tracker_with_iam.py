#!/usr/bin/env python3
"""
Kiro Tracker with IAM Identity Center Integration

IAM Identity Center APIë¥¼ í†µí•´ ì‹¤ì œ ì‚¬ìš©ìëª…ê³¼ ì´ë©”ì¼ì„ ì¡°íšŒí•˜ëŠ” Kiro íŠ¸ë˜ì»¤
"""

# ê³µí†µ ì„¤ì • import
from config import BUCKET_NAME, S3_USER_ACTIVITY_REPORT_PREFIX, SUBSCRIPTION_SERVICE_NAME

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
import boto3
from botocore.exceptions import ClientError
from iam_identity_center_mapper import IAMIdentityCenterMapper, create_user_mapping_interface


# ì§€ì› ë¦¬ì „ ì •ì˜
SUPPORTED_REGIONS = {
    'us-east-1': 'US East (N. Virginia)',
    'us-west-2': 'US West (Oregon)',
    'eu-central-1': 'Europe (Frankfurt)',
    'ap-northeast-1': 'Asia Pacific (Tokyo)',
    'ap-northeast-2': 'Asia Pacific (Seoul)',
    'ap-southeast-1': 'Asia Pacific (Singapore)',
    'ap-southeast-2': 'Asia Pacific (Sydney)'
}


class KiroTrackerWithIAM:
    def __init__(self, bucket_name: str = None, account_id: str = None):
        self.data_dir = Path('data')
        self.data_dir.mkdir(exist_ok=True)
        
        # ë™ì  ì„¤ì •
        self.bucket_name = bucket_name or self._get_default_bucket()
        self.account_id = account_id or self._get_account_id()
        
        # IAM Identity Center ë§¤í¼ ì´ˆê¸°í™”
        if 'user_mapper' not in st.session_state:
            st.session_state.user_mapper = IAMIdentityCenterMapper()
        self.user_mapper = st.session_state.user_mapper
    
    def _get_account_id(self) -> str:
        """í˜„ì¬ AWS ê³„ì • ID ì¡°íšŒ"""
        try:
            sts = boto3.client('sts')
            return sts.get_caller_identity()['Account']
        except Exception as e:
            st.error(f"AWS ê³„ì • ID ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return "123456789012"  # ê¸°ë³¸ê°’
    
    def _get_default_bucket(self) -> str:
        """ê¸°ë³¸ ë²„í‚·ëª… ë°˜í™˜"""
        return BUCKET_NAME
    
    def get_region_prefix(self, region: str) -> str:
        """ë¦¬ì „ë³„ S3 í”„ë¦¬í”½ìŠ¤ ìƒì„±"""
        return f'{S3_USER_ACTIVITY_REPORT_PREFIX}/{self.account_id}/{SUBSCRIPTION_SERVICE_NAME}Logs/by_user_analytic/{region}/'
    
    def list_s3_buckets(self) -> list:
        """S3 ë²„í‚· ëª©ë¡ ì¡°íšŒ"""
        try:
            s3 = boto3.client('s3')
            response = s3.list_buckets()
            buckets = [bucket['Name'] for bucket in response['Buckets']]
            return sorted(buckets)
        except Exception as e:
            st.error(f"S3 ë²„í‚· ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def validate_bucket_structure(self, bucket_name: str) -> dict:
        """ë²„í‚· êµ¬ì¡° ê²€ì¦"""
        try:
            s3 = boto3.client('s3')
            
            # ê¸°ë³¸ ê²½ë¡œ í™•ì¸
            base_prefix = f'{S3_USER_ACTIVITY_REPORT_PREFIX}/{self.account_id}/{SUBSCRIPTION_SERVICE_NAME}Logs/by_user_analytic/'
            
            response = s3.list_objects_v2(
                Bucket=bucket_name,
                Prefix=base_prefix,
                MaxKeys=10
            )
            
            # ë””ë²„ê¹…: ì‘ë‹µ ë‚´ìš© í™•ì¸
            contents = response.get('Contents', [])
            
            # ì¶”ê°€ ë””ë²„ê¹…: ì •í™•í•œ prefixë¡œ ë‹¤ì‹œ ê²€ìƒ‰
            exact_response = s3.list_objects_v2(
                Bucket=bucket_name,
                Prefix=f'{S3_USER_ACTIVITY_REPORT_PREFIX}/{self.account_id}/{SUBSCRIPTION_SERVICE_NAME}Logs/by_user_analytic/',
                MaxKeys=10
            )
            exact_contents = exact_response.get('Contents', [])
            
            if contents or exact_contents:
                files = [obj['Key'] for obj in (contents or exact_contents)]
                regions = set()
                for file_key in files:
                    # ë¦¬ì „ ì¶”ì¶œ: .../by_user_analytic/us-east-1/...
                    parts = file_key.replace(base_prefix, '').split('/')
                    if len(parts) > 0 and parts[0]:
                        regions.add(parts[0])
                
                return {
                    'valid': True,
                    'regions': list(regions),
                    'file_count': len(files),
                    'sample_files': files[:3],
                    'search_path': base_prefix
                }
            else:
                # ë²„í‚· ì „ì²´ êµ¬ì¡° í™•ì¸
                all_response = s3.list_objects_v2(Bucket=bucket_name, MaxKeys=20)
                bucket_files = [obj['Key'] for obj in all_response.get('Contents', [])]
                
                return {
                    'valid': False,
                    'error': 'í•´ë‹¹ ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.',
                    'search_path': base_prefix,
                    'bucket_files': bucket_files[:10],
                    'response_keys': len(contents),
                    'exact_response_keys': len(exact_contents),
                    'account_id_used': self.account_id
                }
                
        except ClientError as e:
            return {
                'valid': False,
                'error': f'ë²„í‚· ì ‘ê·¼ ì˜¤ë¥˜: {e}',
                'search_path': base_prefix
            }
    
    def consolidate_region_data(self, regions: list, days: int = None) -> bool:
        """ì„ íƒëœ ë¦¬ì „ë“¤ì˜ ë°ì´í„°ë¥¼ í†µí•©"""
        try:
            all_dataframes = []
            
            for region in regions:
                st.write(f"ğŸ”„ {SUPPORTED_REGIONS[region]} ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
                
                cmd = [
                    'python3', 'consolidate_kiro_reports_fixed.py',
                    '--bucket', self.bucket_name,
                    '--prefix', self.get_region_prefix(region),
                    '--output', f'data/temp_{region}.csv'
                ]
                
                if days:
                    cmd.extend(['--days', str(days)])
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                
                if result.returncode == 0:
                    region_file = Path(f'data/temp_{region}.csv')
                    if region_file.exists():
                        df = pd.read_csv(region_file)
                        if not df.empty:
                            df['Region'] = region
                            df['RegionName'] = SUPPORTED_REGIONS[region]
                            all_dataframes.append(df)
                        region_file.unlink()
                    st.success(f"âœ… {SUPPORTED_REGIONS[region]} ì™„ë£Œ")
                else:
                    st.warning(f"âš ï¸ {SUPPORTED_REGIONS[region]} ë°ì´í„° ì—†ìŒ")
            
            if not all_dataframes:
                st.error("âŒ ëª¨ë“  ë¦¬ì „ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            consolidated_df = pd.concat(all_dataframes, ignore_index=True)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€í•˜ì—¬ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = self.data_dir / f'consolidated_multiregion_{timestamp}.csv'
            consolidated_df.to_csv(output_file, index=False)
            
            st.success(f"âœ… ë©€í‹° ë¦¬ì „ ë°ì´í„° í†µí•© ì™„ë£Œ: {len(consolidated_df)}í–‰, ì‚¬ìš©ì {consolidated_df['UserId'].nunique()}ëª…")
            return True
            
        except Exception as e:
            st.error(f"âŒ ë°ì´í„° í†µí•© ì˜¤ë¥˜: {e}")
            return False
    
    def load_data_with_user_info(self, file_path: str) -> pd.DataFrame:
        """ë°ì´í„° ë¡œë“œ ë° IAM Identity Center ì‚¬ìš©ì ì •ë³´ ì¶”ê°€"""
        try:
            df = pd.read_csv(file_path)
            if 'ReportDate' in df.columns:
                df['ReportDate'] = pd.to_datetime(df['ReportDate'])
            
            # ê³ ìœ  ì‚¬ìš©ì ID ëª©ë¡
            unique_user_ids = df['UserId'].unique()
            st.info(f"ğŸ“Š CSVì—ì„œ ë°œê²¬ëœ ê³ ìœ  ì‚¬ìš©ì: {len(unique_user_ids)}ëª…")
            
            # IAM Identity Centerì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¼ê´„ ì¡°íšŒ
            with st.spinner(f"IAM Identity Centerì—ì„œ {len(unique_user_ids)}ëª… ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì¤‘..."):
                user_mappings = self.user_mapper.bulk_get_users(unique_user_ids)
            
            # ì‚¬ìš©ì ì •ë³´ë¥¼ DataFrameì— ì¶”ê°€
            df['DisplayName'] = df['UserId'].apply(lambda uid: user_mappings[uid]['display_name'])
            df['Email'] = df['UserId'].apply(lambda uid: user_mappings[uid]['email'])
            df['Username'] = df['UserId'].apply(lambda uid: user_mappings[uid]['username'])
            df['UserSource'] = df['UserId'].apply(lambda uid: user_mappings[uid]['source'])
            
            st.success(f"âœ… ì‚¬ìš©ì ì •ë³´ ë§¤í•‘ ì™„ë£Œ: {len(df)}í–‰, {df['UserId'].nunique()}ëª…")
            return df
            
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def analyze_user_patterns_with_names(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‹¤ì œ ì‚¬ìš©ìëª…ê³¼ í•¨ê»˜ íŒ¨í„´ ë¶„ì„"""
        user_patterns = []
        unique_users = df['UserId'].unique()
        
        st.info(f"ğŸ” íŒ¨í„´ ë¶„ì„ ëŒ€ìƒ ì‚¬ìš©ì: {len(unique_users)}ëª…")
        
        for user_id in unique_users:
            user_data = df[df['UserId'] == user_id]
            
            # ì‚¬ìš©ì ì •ë³´ (ì²« ë²ˆì§¸ í–‰ì—ì„œ ì¶”ì¶œ)
            first_row = user_data.iloc[0]
            display_name = first_row.get('DisplayName', f'User-{user_id[:8]}')
            email = first_row.get('Email', '')
            username = first_row.get('Username', '')
            user_source = first_row.get('UserSource', 'unknown')
            
            # í™œë™ í†µê³„
            total_days = len(user_data)
            first_activity = user_data['ReportDate'].min()
            last_activity = user_data['ReportDate'].max()
            
            # ì‚¬ìš© íŒ¨í„´
            total_chat = user_data['Chat_MessagesSent'].sum()
            total_code = user_data['Chat_AICodeLines'].sum()
            total_inline_suggestions = user_data['Inline_SuggestionsCount'].sum()
            total_inline_accepted = user_data['Inline_AcceptanceCount'].sum()
            total_dev = user_data['Dev_GenerationEventCount'].sum()
            
            # í‰ê·  ê³„ì‚°
            avg_chat_per_day = user_data['Chat_MessagesSent'].mean()
            avg_inline_per_day = user_data['Inline_SuggestionsCount'].mean()
            
            # ìˆ˜ë½ë¥ 
            acceptance_rate = (total_inline_accepted / total_inline_suggestions * 100) if total_inline_suggestions > 0 else 0
            
            # ì‚¬ìš© ìŠ¤íƒ€ì¼ ë¶„ë¥˜
            if avg_chat_per_day > 50:
                usage_style = "ğŸ”¥ Heavy Chat User"
            elif avg_inline_per_day > 50:
                usage_style = "âš¡ Heavy Code Assistant"
            elif avg_chat_per_day > 10:
                usage_style = "ğŸ“ Regular User"
            else:
                usage_style = "ğŸŒ± Light User"
            
            user_patterns.append({
                'UserId': user_id,
                'DisplayName': display_name,
                'Email': email,
                'Username': username,
                'UserSource': user_source,
                'TotalDays': total_days,
                'FirstActivity': first_activity.strftime('%Y-%m-%d') if pd.notna(first_activity) else 'N/A',
                'LastActivity': last_activity.strftime('%Y-%m-%d') if pd.notna(last_activity) else 'N/A',
                'TotalChatMessages': int(total_chat),
                'TotalCodeLines': int(total_code),
                'TotalInlineSuggestions': int(total_inline_suggestions),
                'TotalInlineAccepted': int(total_inline_accepted),
                'AcceptanceRate': round(acceptance_rate, 1),
                'TotalDevEvents': int(total_dev),
                'AvgChatPerDay': round(avg_chat_per_day, 1),
                'AvgInlinePerDay': round(avg_inline_per_day, 1),
                'UsageStyle': usage_style
            })
        
        return pd.DataFrame(user_patterns)


def main():
    st.set_page_config(
        page_title="Kiro Tracker with IAM",
        page_icon="ğŸ¯",
        layout="wide"
    )
    
    st.title("ğŸ¯ Kiro Tracker with IAM Identity Center")
    st.markdown("IAM Identity Center ì—°ë™ìœ¼ë¡œ ì‹¤ì œ ì‚¬ìš©ìëª…ê³¼ ì´ë©”ì¼ í‘œì‹œ")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    # íŠ¸ë˜ì»¤ ì´ˆê¸°í™” (ê³ ì •ëœ ë²„í‚·ëª…ê³¼ STSë¡œ ìë™ Account ID ì¡°íšŒ)
    tracker = KiroTrackerWithIAM()
    
    # ë²„í‚· êµ¬ì¡° ê²€ì¦
    if st.sidebar.button("ğŸ” ë²„í‚· êµ¬ì¡° ê²€ì¦"):
        with st.spinner("ë²„í‚· êµ¬ì¡° ê²€ì¦ ì¤‘..."):
            validation = tracker.validate_bucket_structure(tracker.bucket_name)
            
            if validation['valid']:
                st.sidebar.success(f"âœ… ë²„í‚· êµ¬ì¡° ìœ íš¨")
                st.sidebar.info(f"ë°œê²¬ëœ ë¦¬ì „: {', '.join(validation['regions'])}")
                st.sidebar.info(f"íŒŒì¼ ìˆ˜: {validation['file_count']}ê°œ")
            else:
                st.sidebar.error(f"âŒ {validation['error']}")
                st.sidebar.code(f"ê²€ìƒ‰ ê²½ë¡œ: {validation.get('search_path', 'N/A')}")
                
                if 'bucket_files' in validation:
                    st.sidebar.write("**ë²„í‚· ë‚´ ì‹¤ì œ íŒŒì¼ë“¤:**")
                    for file in validation['bucket_files']:
                        st.sidebar.text(file)
    
    # í˜„ì¬ ì„¤ì • í‘œì‹œ
    st.sidebar.markdown("---")
    st.sidebar.markdown("**í˜„ì¬ ì„¤ì •:**")
    st.sidebar.code(f"ë²„í‚·: {tracker.bucket_name}")
    st.sidebar.code(f"ê³„ì •: {tracker.account_id}")
    
    # ========== S3 ë°ì´í„° ìˆ˜ì§‘ ì„¹ì…˜ ==========
    st.sidebar.subheader("ğŸ“¥ S3 ë°ì´í„° ìˆ˜ì§‘")
    
    # ë¦¬ì „ ì„ íƒ
    selected_regions = st.sidebar.multiselect(
        "ìˆ˜ì§‘í•  ë¦¬ì „ ì„ íƒ",
        options=list(SUPPORTED_REGIONS.keys()),
        default=['us-east-1'],
        format_func=lambda x: f"{x} ({SUPPORTED_REGIONS[x]})"
    )
    
    # S3 ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì •
    collect_date_option = st.sidebar.radio("ìˆ˜ì§‘ ê¸°ê°„", ["ì „ì²´ ê¸°ê°„", "ìµœê·¼ Nì¼"], key="collect_date")
    collect_days = None
    if collect_date_option == "ìµœê·¼ Nì¼":
        collect_days = st.sidebar.slider("ìˆ˜ì§‘í•  ì¼ìˆ˜", 1, 90, 30, key="collect_days")
    
    # ë°ì´í„° í†µí•© ë²„íŠ¼
    if st.sidebar.button("ğŸ”„ ë¦¬ì „ ë°ì´í„° í†µí•©"):
        if selected_regions:
            with st.spinner("ë©€í‹° ë¦¬ì „ ë°ì´í„° í†µí•© ì¤‘..."):
                success = tracker.consolidate_region_data(selected_regions, collect_days)
                if success:
                    st.rerun()
    
    st.sidebar.markdown("---")
    
    # ========== ë°ì´í„° ë¶„ì„ ì„¹ì…˜ ==========
    st.sidebar.subheader("ğŸ“‚ ë°ì´í„° íŒŒì¼")
    
    # íŒŒì¼ ëª©ë¡ì„ ë§¤ë²ˆ ìƒˆë¡œ ì¡°íšŒí•˜ê³  ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
    csv_files = sorted(list(tracker.data_dir.glob("*.csv")), key=lambda x: x.stat().st_mtime, reverse=True)
    
    if not csv_files:
        st.info("""
        ğŸ’¡ **ì‹œì‘í•˜ê¸°:**
        1. ë¦¬ì „ ì„ íƒ í›„ "ë¦¬ì „ ë°ì´í„° í†µí•©" í´ë¦­
        2. ë˜ëŠ” ê¸°ì¡´ CSV íŒŒì¼ì„ data/ í´ë”ì— ë°°ì¹˜
        """)
        return
    
    csv_options = [f"{f.name} ({datetime.fromtimestamp(f.stat().st_mtime).strftime('%m-%d %H:%M')})" for f in csv_files]
    csv_names = [f.name for f in csv_files]
    
    selected_index = st.sidebar.selectbox("CSV íŒŒì¼ ì„ íƒ (ìµœì‹ ìˆœ)", range(len(csv_options)), format_func=lambda x: csv_options[x])
    selected_csv = csv_names[selected_index]
    selected_file_path = tracker.data_dir / selected_csv
    
    # ì¡°íšŒ ê¸°ê°„ (ë¡œë“œëœ ë°ì´í„° ë‚´ì—ì„œ í•„í„°ë§)
    st.sidebar.subheader("ğŸ“… ì¡°íšŒ ê¸°ê°„")
    display_date_option = st.sidebar.radio("ì¡°íšŒ ê¸°ê°„", ["ì „ì²´ ê¸°ê°„", "ìµœê·¼ Nì¼"], key="display_date")
    display_days = None
    if display_date_option == "ìµœê·¼ Nì¼":
        display_days = st.sidebar.slider("ì¡°íšŒí•  ì¼ìˆ˜", 1, 90, 30, key="display_days")
    
    # ë¶„ì„ ëª¨ë“œ ì„ íƒ
    st.sidebar.subheader("ğŸ“Š ë¶„ì„ ëª¨ë“œ")
    analysis_mode = st.sidebar.radio(
        "ë¶„ì„ ìœ í˜•",
        ["ì‚¬ìš©ì ë¶„ì„", "IAM ë§¤í•‘ ê´€ë¦¬", "ê°œë³„ ì‚¬ìš©ì ìƒì„¸"]
    )
    
    # IAM Identity Center ì—°ê²° ìƒíƒœ
    mapper_stats = tracker.user_mapper.get_cache_stats()
    connection_status = "ğŸŸ¢ ì—°ê²°ë¨" if mapper_stats['identity_store_connected'] else "ğŸ”´ ë¯¸ì—°ê²°"
    st.sidebar.write(f"**IAM Identity Center**: {connection_status}")
    st.sidebar.write(f"**ë§¤í•‘ëœ ì‚¬ìš©ì**: {mapper_stats['total_users']}ëª…")
    
    # ë¶„ì„ ëª¨ë“œë³„ ì²˜ë¦¬
    if analysis_mode == "IAM ë§¤í•‘ ê´€ë¦¬":
        create_user_mapping_interface()
        return
    
    # ë°ì´í„° ë¡œë“œ
    df = tracker.load_data_with_user_info(selected_file_path)
    
    if df.empty:
        st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì„ íƒëœ ë¦¬ì „ë§Œ í•„í„°ë§
    if 'Region' in df.columns and selected_regions:
        df = df[df['Region'].isin(selected_regions)]
    
    # ë‚ ì§œ í•„í„°ë§ ì ìš© (ë¡œë“œëœ ë°ì´í„°ì—ì„œ ì¡°íšŒ ê¸°ê°„ ì ìš©)
    if display_days and 'ReportDate' in df.columns:
        cutoff_date = datetime.now() - timedelta(days=display_days)
        df = df[df['ReportDate'] >= cutoff_date]
        st.sidebar.info(f"ğŸ“… {cutoff_date.strftime('%Y-%m-%d')} ì´í›„ ë°ì´í„°ë§Œ ì¡°íšŒ")
    
    if df.empty:
        st.warning("âš ï¸ ì„ íƒëœ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ë³¸ ì •ë³´
    st.header("ğŸ“‹ ë°ì´í„° ê°œìš”")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ í–‰ ìˆ˜", len(df))
    with col2:
        st.metric("ì‚¬ìš©ì ìˆ˜", df['UserId'].nunique())
    with col3:
        region_count = df['Region'].nunique() if 'Region' in df.columns else 1
        st.metric("ë¦¬ì „ ìˆ˜", region_count)
    with col4:
        iam_users = len(df[df['UserSource'] == 'iam_identity_center']['UserId'].unique())
        st.metric("IAM ì—°ë™ ì‚¬ìš©ì", iam_users)
    
    if analysis_mode == "ì‚¬ìš©ì ë¶„ì„":
        st.header("ğŸ‘¥ ì‚¬ìš©ì ë¶„ì„ (ì‹¤ì œ ì´ë¦„ í¬í•¨)")
        
        # ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
        user_patterns = tracker.analyze_user_patterns_with_names(df)
        
        # ì „ì²´ í†µê³„
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_chat = user_patterns['TotalChatMessages'].sum()
            st.metric("ì´ Chat ë©”ì‹œì§€", f"{total_chat:,}")
        
        with col2:
            total_code = user_patterns['TotalCodeLines'].sum()
            st.metric("ì´ ì½”ë“œ ë¼ì¸", f"{total_code:,}")
        
        with col3:
            avg_acceptance = user_patterns['AcceptanceRate'].mean()
            st.metric("í‰ê·  ìˆ˜ë½ë¥ ", f"{avg_acceptance:.1f}%")
        
        with col4:
            iam_connected = len(user_patterns[user_patterns['UserSource'] == 'iam_identity_center'])
            st.metric("IAM ì—°ë™ ì‚¬ìš©ì", iam_connected)
        
        # ì‚¬ìš©ìë³„ ìƒì„¸ í…Œì´ë¸”
        st.subheader("ğŸ‘¤ ì‚¬ìš©ìë³„ ìƒì„¸ ì •ë³´")
        
        # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
        display_columns = [
            'DisplayName', 'Email', 'Username', 'UserSource',
            'TotalChatMessages', 'TotalCodeLines', 'AcceptanceRate',
            'TotalDays', 'UsageStyle', 'FirstActivity', 'LastActivity'
        ]
        
        # ì •ë ¬ ì˜µì…˜
        sort_options = ['TotalChatMessages', 'TotalCodeLines', 'AcceptanceRate', 'TotalDays']
        sort_column = st.selectbox("ì •ë ¬ ê¸°ì¤€", sort_options)
        sort_ascending = st.checkbox("ì˜¤ë¦„ì°¨ìˆœ", value=False)
        
        sorted_patterns = user_patterns.sort_values(sort_column, ascending=sort_ascending)
        
        # ì¸ë±ìŠ¤ë¥¼ 1ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì¬ì„¤ì •
        display_df = sorted_patterns[display_columns].copy()
        display_df.index = range(1, len(display_df) + 1)
        
        st.dataframe(
            display_df,
            use_container_width=True,
            column_config={
                "DisplayName": "í‘œì‹œëª…",
                "Email": "ì´ë©”ì¼",
                "Username": "ì‚¬ìš©ìëª…",
                "UserSource": "ë°ì´í„° ì†ŒìŠ¤",
                "TotalChatMessages": "Chat ë©”ì‹œì§€",
                "TotalCodeLines": "ì½”ë“œ ë¼ì¸",
                "AcceptanceRate": "ìˆ˜ë½ë¥  (%)",
                "TotalDays": "í™œë™ ì¼ìˆ˜",
                "UsageStyle": "ì‚¬ìš© ìŠ¤íƒ€ì¼",
                "FirstActivity": "ì²« í™œë™",
                "LastActivity": "ë§ˆì§€ë§‰ í™œë™"
            }
        )
        
        # ì‹œê°í™”
        st.subheader("ğŸ“ˆ ì‹œê°í™”")
        
        # ========== 1í–‰: 2ì—´ ë ˆì´ì•„ì›ƒ ==========
        col_left, col_right = st.columns(2)
        
        with col_left:
            # ìƒìœ„ 10ëª… Chat ë©”ì‹œì§€
            fig1 = px.bar(
                sorted_patterns.head(10),
                x='DisplayName',
                y='TotalChatMessages',
                title='ìƒìœ„ 10ëª… ì‚¬ìš©ìë³„ Chat ë©”ì‹œì§€ ìˆ˜',
                labels={'TotalChatMessages': 'Chat ë©”ì‹œì§€ ìˆ˜', 'DisplayName': 'ì‚¬ìš©ìëª…'}
            )
            fig1.update_layout(xaxis_tickangle=45)
            st.plotly_chart(fig1, use_container_width=True)
        
        with col_right:
            # ê¸°ëŠ¥ë³„ ì‚¬ìš© ë¹„ìœ¨ ë„ë„› ì°¨íŠ¸
            feature_usage = []
            
            chat_count = df['Chat_MessagesSent'].sum()
            if chat_count > 0:
                feature_usage.append({'Feature': 'Chat', 'Count': int(chat_count)})
            
            inline_count = df['Inline_SuggestionsCount'].sum()
            if inline_count > 0:
                feature_usage.append({'Feature': 'Inline ì½”ë“œ ì œì•ˆ', 'Count': int(inline_count)})
            
            if 'CodeReview_SucceededEventCount' in df.columns:
                codereview_count = df['CodeReview_SucceededEventCount'].sum() + df['CodeReview_FailedEventCount'].sum()
                if codereview_count > 0:
                    feature_usage.append({'Feature': 'Code Review', 'Count': int(codereview_count)})
            
            if 'TestGeneration_EventCount' in df.columns:
                testgen_count = df['TestGeneration_EventCount'].sum()
                if testgen_count > 0:
                    feature_usage.append({'Feature': 'í…ŒìŠ¤íŠ¸ ìƒì„±', 'Count': int(testgen_count)})
            
            if 'DocGeneration_EventCount' in df.columns:
                docgen_count = df['DocGeneration_EventCount'].sum()
                if docgen_count > 0:
                    feature_usage.append({'Feature': 'ë¬¸ì„œ ìƒì„±', 'Count': int(docgen_count)})
            
            if 'Dev_GenerationEventCount' in df.columns:
                dev_count = df['Dev_GenerationEventCount'].sum()
                if dev_count > 0:
                    feature_usage.append({'Feature': 'Dev Agent', 'Count': int(dev_count)})
            
            if feature_usage:
                usage_df = pd.DataFrame(feature_usage)
                fig_usage = px.pie(
                    usage_df,
                    values='Count',
                    names='Feature',
                    title='ê¸°ëŠ¥ë³„ ì‚¬ìš© ë¹„ìœ¨',
                    hole=0.4
                )
                fig_usage.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig_usage, use_container_width=True)
        
        # ========== 2í–‰: ì¼ë³„ íŠ¸ë Œë“œ (ì „ì²´ ë„ˆë¹„) ==========
        if 'ReportDate' in df.columns:
            daily_df = df.groupby('ReportDate').agg({
                'Chat_MessagesSent': 'sum',
                'Inline_SuggestionsCount': 'sum',
                'Inline_AcceptanceCount': 'sum',
                'Chat_AICodeLines': 'sum'
            }).reset_index()
            daily_df = daily_df.sort_values('ReportDate')
            
            fig_trend = go.Figure()
            
            fig_trend.add_trace(go.Scatter(
                x=daily_df['ReportDate'],
                y=daily_df['Chat_MessagesSent'],
                mode='lines+markers',
                name='Chat ë©”ì‹œì§€',
                line=dict(color='#1f77b4')
            ))
            
            fig_trend.add_trace(go.Scatter(
                x=daily_df['ReportDate'],
                y=daily_df['Inline_SuggestionsCount'],
                mode='lines+markers',
                name='Inline ì œì•ˆ',
                line=dict(color='#ff7f0e')
            ))
            
            fig_trend.add_trace(go.Scatter(
                x=daily_df['ReportDate'],
                y=daily_df['Inline_AcceptanceCount'],
                mode='lines+markers',
                name='Inline ìˆ˜ë½',
                line=dict(color='#2ca02c')
            ))
            
            fig_trend.update_layout(
                title='ì¼ë³„ ì£¼ìš” ì§€í‘œ íŠ¸ë Œë“œ',
                xaxis_title='ë‚ ì§œ',
                yaxis_title='íšŸìˆ˜',
                hovermode='x unified',
                legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
            )
            st.plotly_chart(fig_trend, use_container_width=True)
        
        # ========== 3í–‰: Inline ì œì•ˆ vs ìˆ˜ë½ë¥  (ì „ì²´ ë„ˆë¹„) ==========
        fig2 = px.scatter(
            user_patterns,
            x='TotalInlineSuggestions',
            y='AcceptanceRate',
            size='TotalCodeLines',
            hover_data=['DisplayName', 'Email'],
            title='Inline ì œì•ˆ ìˆ˜ vs ìˆ˜ë½ë¥  (í¬ê¸°: ì½”ë“œ ë¼ì¸ ìˆ˜)',
            labels={
                'TotalInlineSuggestions': 'Inline ì œì•ˆ ìˆ˜',
                'AcceptanceRate': 'ìˆ˜ë½ë¥  (%)'
            }
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    else:  # ê°œë³„ ì‚¬ìš©ì ìƒì„¸
        st.header("ğŸ‘¤ ê°œë³„ ì‚¬ìš©ì ìƒì„¸ ë¶„ì„")
        
        users = df['UserId'].unique()
        
        # ì‚¬ìš©ì ì„ íƒ (ì‹¤ì œ ì´ë¦„ìœ¼ë¡œ í‘œì‹œ)
        user_options = []
        for uid in users:
            display_name = df[df['UserId'] == uid]['DisplayName'].iloc[0]
            email = df[df['UserId'] == uid]['Email'].iloc[0]
            user_label = f"{display_name}"
            if email:
                user_label += f" ({email})"
            user_options.append((uid, user_label))
        
        selected_user = st.selectbox(
            "ë¶„ì„í•  ì‚¬ìš©ì ì„ íƒ",
            users,
            format_func=lambda uid: next(label for u, label in user_options if u == uid)
        )
        
        if selected_user:
            user_data = df[df['UserId'] == selected_user].copy()
            user_data = user_data.sort_values('ReportDate')
            
            # ì‚¬ìš©ì ì •ë³´
            first_row = user_data.iloc[0]
            display_name = first_row['DisplayName']
            email = first_row['Email']
            username = first_row['Username']
            user_source = first_row['UserSource']
            
            # ì‚¬ìš©ì ê¸°ë³¸ ì •ë³´
            st.subheader(f"ğŸ‘¤ {display_name}")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ì´ë©”ì¼**: {email or 'ì—†ìŒ'}")
                st.write(f"**ì‚¬ìš©ìëª…**: {username or 'ì—†ìŒ'}")
            with col2:
                st.write(f"**ë°ì´í„° ì†ŒìŠ¤**: {user_source}")
                st.write(f"**UserId**: {selected_user[:12]}...")
            
            # í™œë™ í†µê³„
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("í™œë™ ì¼ìˆ˜", len(user_data))
            
            with col2:
                total_chat = user_data['Chat_MessagesSent'].sum()
                st.metric("ì´ Chat ë©”ì‹œì§€", f"{total_chat:,}")
            
            with col3:
                total_code = user_data['Chat_AICodeLines'].sum()
                st.metric("ì´ ì½”ë“œ ë¼ì¸", f"{total_code:,}")
            
            with col4:
                suggestions = user_data['Inline_SuggestionsCount'].sum()
                accepted = user_data['Inline_AcceptanceCount'].sum()
                rate = (accepted / suggestions * 100) if suggestions > 0 else 0
                st.metric("Inline ìˆ˜ë½ë¥ ", f"{rate:.1f}%")
            
            # ì¼ë³„ í™œë™ ì°¨íŠ¸
            st.subheader("ğŸ“ˆ ì¼ë³„ í™œë™ íŒ¨í„´")
            
            fig = px.line(
                user_data,
                x='ReportDate',
                y='Chat_MessagesSent',
                title=f'{display_name} - ì¼ë³„ Chat ë©”ì‹œì§€ ì¶”ì´',
                labels={'Chat_MessagesSent': 'Chat ë©”ì‹œì§€ ìˆ˜', 'ReportDate': 'ë‚ ì§œ'}
            )
            fig.update_traces(mode='lines+markers')
            st.plotly_chart(fig, use_container_width=True)
            
            # ì¼ë³„ ìƒì„¸ ë°ì´í„°
            st.subheader("ğŸ“… ì¼ë³„ ìƒì„¸ ë°ì´í„°")
            
            display_columns = ['ReportDate', 'Chat_MessagesSent', 'Chat_AICodeLines',
                             'Inline_SuggestionsCount', 'Inline_AcceptanceCount']
            
            if 'RegionName' in user_data.columns:
                display_columns.insert(1, 'RegionName')
            
            # í…Œì´ë¸” ì¸ë±ìŠ¤ë¥¼ 1ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì„¤ì •
            display_df = user_data[display_columns].copy()
            display_df.index = range(1, len(display_df) + 1)
            
            st.dataframe(display_df, use_container_width=True)
            
            # CSV ë‹¤ìš´ë¡œë“œ
            user_csv = user_data.to_csv(index=False)
            st.download_button(
                label=f"ğŸ“¥ {display_name} ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
                data=user_csv,
                file_name=f"kiro_{display_name.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )


if __name__ == "__main__":
    main()
